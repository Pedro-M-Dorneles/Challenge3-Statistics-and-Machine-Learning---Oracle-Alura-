{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84ded5a1",
   "metadata": {},
   "source": [
    "# TelecomX_BR Parte 2 - Criação de um Modelo para identificar a evasão de cliêntes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461f7a9f",
   "metadata": {},
   "source": [
    "# Tratamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c3a2fe",
   "metadata": {},
   "source": [
    "\n",
    "### 📥 Importação de Bibliotecas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e6fb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b805f73a",
   "metadata": {},
   "source": [
    "### 📂 Carregamento e Visualização Inicial dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eba2d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo os dados\n",
    "dados = pd.read_csv('G:/Meu Drive/Oracle_alura/Estatistica_ML/Challenge_3/dados/dados_tratados.csv')\n",
    "print(dados.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04d9cee",
   "metadata": {},
   "source": [
    "### 🧹 Limpeza de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9562b5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removendo valores nulos\n",
    "dados.fillna(dados.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "#Removendo colunas inuteis\n",
    "dados.drop(columns='customerID', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810c9c80",
   "metadata": {},
   "source": [
    "### 🔁 Encoding de Variáveis Binárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d037090",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizando o encoding das variaveis\n",
    "print(dados.nunique())\n",
    "\n",
    "#Convertendo as variaveis explicativas binarias\n",
    "dados['Churn'].replace({'No': 0, 'Yes': 1},inplace=True)\n",
    "dados['customer.gender'].replace({'Female': 0, 'Male': 1}, inplace=True)\n",
    "dados['customer.Partner'].replace({'No': 0, 'Yes': 1}, inplace=True)\n",
    "dados['customer.Dependents'].replace({'No': 0, 'Yes': 1}, inplace=True)\n",
    "dados['phone.PhoneService'].replace({'No': 0, 'Yes': 1}, inplace=True)\n",
    "dados['account.PaperlessBilling'].replace({'No': 0, 'Yes': 1}, inplace=True)\n",
    "\n",
    "#Criando uma coluna pra quem tem ou não serviço se phone ou internete, transformando as originais em binarias\n",
    "dados['has.PhoneService'] = dados['phone.MultipleLines'].map(lambda x: 0 if x=='No phone service' else 1)\n",
    "dados['phone.MultipleLines'].replace({'No': 0, 'Yes': 1, 'No phone service': 0},inplace=True)\n",
    "\n",
    "colunas = ['internet.OnlineSecurity','internet.OnlineBackup','internet.DeviceProtection','internet.TechSupport','internet.StreamingTV','internet.StreamingMovies']\n",
    "dados[colunas]=dados[colunas].replace({'No': 0, 'Yes': 1, 'No internet service': 0})\n",
    "dados['has.InternetService'] = dados[colunas].apply(lambda linha: 0 if all(valor == 0 for valor in linha) else 1, axis=1)\n",
    "print(dados.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5555b2cf",
   "metadata": {},
   "source": [
    "### 🧠 One-Hot Encoding para Variáveis Não Binárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d6a7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertendo as explicativas nao binarias utilizando o One hot encoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#Separando variaveis explicativas da independente\n",
    "X  = dados.drop(columns='Churn')\n",
    "Y  = dados['Churn']\n",
    "#Salvando as colunas originais\n",
    "colunas = X.columns\n",
    "one_hot = make_column_transformer((OneHotEncoder(drop='if_binary'),['account.Contract','account.PaymentMethod','internet.InternetService']),remainder='passthrough',sparse_threshold=0)\n",
    "\n",
    "#Aplicando a transformação nas variaveis explicativas\n",
    "X = one_hot.fit_transform(X)\n",
    "X = pd.DataFrame(X, columns=one_hot.get_feature_names_out(colunas))\n",
    "print(Y)\n",
    "print(X.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5aa2f7e",
   "metadata": {},
   "source": [
    "### 🔍 Análise de Correlação com a Variável Churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f056be0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observando a proporção de evasão da variavel dependente\n",
    "print(Y.value_counts(normalize=True))\n",
    "#73.5% não saiu, 26.5% saiu\n",
    "\n",
    "\n",
    "#Realizando a análise da correlação dos parâmetros\n",
    "correlacoes = {}\n",
    "for coluna in X.columns:\n",
    "    correlacoes[coluna] = pd.Series(X[coluna]).corr(Y)\n",
    "\n",
    "# Convertendo para DataFrame para facilitar a visualização\n",
    "correlacoes_df = pd.DataFrame.from_dict(correlacoes, orient='index', columns=['Correlação com Churn'])\n",
    "correlacoes_df = correlacoes_df.sort_values(by='Correlação com Churn', ascending=False)\n",
    "\n",
    "# Plotando as correlações\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x=correlacoes_df['Correlação com Churn'], y=correlacoes_df.index, palette='coolwarm')\n",
    "plt.title('Correlação das variáveis com Churn')\n",
    "plt.xlabel('Correlação')\n",
    "plt.ylabel('Variável')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc647602",
   "metadata": {},
   "source": [
    "![Correlação das variáveis com Churn](<../gráficos/correlação com churn.png>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8397ee5f",
   "metadata": {},
   "source": [
    "### ⚖️ Normalização dos Dados com MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5421a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fazendo dados normalizados\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#Inicializando o objeto da normalização em uma variável\n",
    "normalizacao = MinMaxScaler()\n",
    "colunas = X.columns\n",
    "\n",
    "#Aplicando a transformação nos dados de treinamento com a função .fit_transform()\n",
    "X_normal = pd.DataFrame(normalizacao.fit_transform(X), columns=colunas)\n",
    "\n",
    "#Visualizando as informações normalizadas\n",
    "fig = px.histogram(X_normal, x='onehotencoder__account.Contract_Month-to-month', text_auto=True, color=Y, barmode='group')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb6432b",
   "metadata": {},
   "source": [
    "![Dados Normalizados](<../gráficos/dados normalizados.png>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555caa20",
   "metadata": {},
   "source": [
    "# Modelo RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03b769c",
   "metadata": {},
   "source": [
    "### 📥 Importação de Bibliotecas e Dados Tratados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff76a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from Tratamento import X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8375b8fe",
   "metadata": {},
   "source": [
    "### 📊 Divisão dos Dados e Balanceamento com SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5152db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizando a divisão dos dados com 80% usado para treino\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size= 0.20)\n",
    "\n",
    "\n",
    "#Balanceamento apenas dos dados de treino com SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "X_train, Y_train = oversample.fit_resample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f1a415",
   "metadata": {},
   "source": [
    "### 🌲 Criação e Avaliação Inicial do Modelo Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce683093",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando o modelo de arvore e utilizando a validação cruzada\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "\n",
    "#Criando um modelo\n",
    "floresta = RandomForestClassifier(max_depth = 10, random_state=5)\n",
    "#Aplicando o floresta\n",
    "floresta.fit(X_train, Y_train)\n",
    "print('\\nDesempenho do modelo' ,floresta.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5843801e",
   "metadata": {},
   "source": [
    "### 🔁 Validação Cruzada com Pipeline + SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680ec98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validação cruzada com pipeline\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "\n",
    "pipeline = imbpipeline([\n",
    "    ('smote', SMOTE(random_state=5)),\n",
    "    ('modelo', RandomForestClassifier(max_depth=10, random_state=5))\n",
    "])\n",
    "skf = StratifiedKFold(n_splits=10,shuffle=True,random_state=5)\n",
    "cv_resultados = cross_validate(pipeline, X, Y, cv=skf, scoring='f1')\n",
    "print('\\nResultados da validação cruzada\\n', cv_resultados)\n",
    "\n",
    "#Criando uma função para obter o intervalo de confiança\n",
    "def intervalo_conf(resultados):\n",
    "    media = resultados['test_score'].mean()\n",
    "    desvio_padrao = resultados['test_score'].std()\n",
    "    print(f'\\nIntervalo de confiança: [{media - 2*desvio_padrao}, {min(media + 2*desvio_padrao, 1)}]')\n",
    "intervalo_conf(cv_resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6661359",
   "metadata": {},
   "source": [
    "### 🧪 Métricas de Avaliação do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cdd8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observando as métricas do modelo\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "Y_prev = floresta.predict(X_test)\n",
    "print('Acurácia: ', accuracy_score(Y_test, Y_prev))\n",
    "print('Precisão: ', precision_score(Y_test, Y_prev))\n",
    "print('Recall: ', recall_score(Y_test, Y_prev))\n",
    "print('F1 Score: ', f1_score(Y_test, Y_prev))\n",
    "\n",
    "#Construindo a curva a partir das previsões feitas pelo modelo\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "RocCurveDisplay.from_predictions(Y_test, Y_prev, name='Arvore de decisão')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc909574",
   "metadata": {},
   "source": [
    "![Curva ROC](<../gráficos/curva ROC.png>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d610d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Avaliando com a matriz de confusão\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "#Criando a matriz\n",
    "matriz_confusao = confusion_matrix(Y_test, Y_prev)\n",
    "#Visualizando a matriz de confusão\n",
    "visualizacao = ConfusionMatrixDisplay(matriz_confusao, display_labels=['Deixou o serviço', 'Não deixou o serviço'])\n",
    "visualizacao.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ddb921",
   "metadata": {},
   "source": [
    "![Matriz de confusão 1](<../gráficos/matriz de confusão 1.png>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcc1da1",
   "metadata": {},
   "source": [
    "### 🧠 Importância das Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492b6643",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entendendo agora as features mais importantes do modelo de floresta, as 10 primeiras\n",
    "from yellowbrick.model_selection import FeatureImportances\n",
    "viz =  FeatureImportances(floresta, relative=False)#O parâmetro relative=False define a importancia absoluta\n",
    "viz.fit(X_train, Y_train)\n",
    "viz.show()\n",
    "\n",
    "importances = floresta.feature_importances_\n",
    "#Transformando em um data frame e ordenando os valores para melhorar a visualização\n",
    "feature_importances = pd.DataFrame({'Features': X.columns, 'Importances': importances})\n",
    "feature_importances.sort_values('Importances', ascending=False, inplace=True)\n",
    "print('Importancia de cada feature',feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12991cbd",
   "metadata": {},
   "source": [
    "![Matriz de confusão 1](<../gráficos/features importantes.png>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8408a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para calcular as métricas de classificação\n",
    "def calcular_metricas_classificacao(y_test, y_pred):\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    \n",
    "    metricas = {\n",
    "        'Acurácia': round(acc, 4),\n",
    "        'Precisão': round(prec, 4),\n",
    "        'Recall': round(rec, 4),\n",
    "        'F1 Score': round(f1, 4)\n",
    "    }\n",
    "    return metricas\n",
    "\n",
    "# Redeterminando o modelo com base nas features mais importantes\n",
    "# Criando um data frame onde os índices são as métricas\n",
    "results_df = pd.DataFrame(index=['Acurácia', 'Precisão', 'Recall', 'F1 Score'])\n",
    "\n",
    "# Recriando o modelo da floresta\n",
    "model_selected_features = RandomForestClassifier(random_state=5, max_depth=5)\n",
    "\n",
    "# Criando um loop, para pegar as 1 a 19 features mais importantes\n",
    "for count in range(1, 20):\n",
    "    # Selecionando os nomes das features com base no data frame das features mais importantes\n",
    "    selected_features = feature_importances['Features'].values[:count]\n",
    "    # Pegando os dados de treino e teste de acordo com as features selecionadas\n",
    "    X_train_selected = X_train[selected_features]\n",
    "    X_test_selected = X_test[selected_features]\n",
    "    # Ajustando o modelo com esses novos dados de treino\n",
    "    model_selected_features.fit(X_train_selected, Y_train)\n",
    "    # Fazendo a previsão do modelo com base nos novos dados de teste\n",
    "    Y_pred = model_selected_features.predict(X_test_selected)\n",
    "    # Calculando as novas métricas\n",
    "    metricas = calcular_metricas_classificacao(Y_test, Y_pred)\n",
    "    # Colocando o resultado das métricas em um data frame\n",
    "    results_df[count] = list(metricas.values())\n",
    "print('\\nResultados:\\n', results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbac3e86",
   "metadata": {},
   "source": [
    "### ✅ Reavaliação com as 17 Melhores Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ec10e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mantendo apenas as 17 primeiras features\n",
    "selected_features = feature_importances['Features'].values[:17]\n",
    "X_select_features = X[selected_features]\n",
    "\n",
    "\n",
    "#Separando os dados de treino e teste apenas com essas features\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_select_features, Y, random_state=5, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f877398c",
   "metadata": {},
   "source": [
    "### 🔍 Otimização de Hiperparâmetros com GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135e8a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recriando o pipeline\n",
    "pipeline = imbpipeline([\n",
    "    ('smote', SMOTE(random_state=5)),\n",
    "    ('modelo', RandomForestClassifier(random_state=5, class_weight={0: 2, 1: 1}))\n",
    "])\n",
    "\n",
    "#Fazendo o modelo só que com os hiperparâmetros\n",
    "#Grid dos parâmetros do RandomForestClassifier\n",
    "param_grid = {\n",
    "    'modelo__n_estimators': [100, 150, 200],\n",
    "    'modelo__max_depth': [5, 10, 15],\n",
    "    'modelo__min_samples_split': [2, 4, 6],\n",
    "    'modelo__min_samples_leaf': [1, 2, 3]\n",
    "}\n",
    "\n",
    "#Importando o GridSearchCV e criando o modelo\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "floresta_grid = GridSearchCV(pipeline, param_grid=param_grid, scoring='f1', cv=skf)\n",
    "\n",
    "#Treinando o modelo\n",
    "floresta_grid.fit(X_train, Y_train)\n",
    "#Visualizando os melhores parâmetros com o metodo .best_params_\n",
    "print(floresta_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17da44f3",
   "metadata": {},
   "source": [
    "### 📋 Avaliação Final do Modelo Otimizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e937335",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observando novamente as métricas\n",
    "Y_prev = floresta_grid.predict(X_test)\n",
    "print('Acurácia: ', accuracy_score(Y_test, Y_prev))\n",
    "print('Precisão: ', precision_score(Y_test, Y_prev))\n",
    "print('Recall: ', recall_score(Y_test, Y_prev))\n",
    "print('F1 Score: ', f1_score(Y_test, Y_prev))\n",
    "\n",
    "#visualizando a matriz de confusão de novo\n",
    "matriz_confusao = confusion_matrix(Y_test, Y_prev)\n",
    "visualizacao = ConfusionMatrixDisplay(matriz_confusao, display_labels=['Deixou o serviço', 'Não deixou o serviço'])\n",
    "visualizacao.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7905d7",
   "metadata": {},
   "source": [
    "![Matriz de confusão 2](<../gráficos/matriz de confusão 2.png>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01adf365",
   "metadata": {},
   "source": [
    "# Modelo KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487da144",
   "metadata": {},
   "source": [
    "### 📥 Importação de Bibliotecas e Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a6fd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from Tratamento import Y, X_normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b3f078",
   "metadata": {},
   "source": [
    "### 📊 Divisão dos Dados Normalizados e Balanceamento com SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c15e7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_normal, Y, test_size= 0.20)\n",
    "\n",
    "\n",
    "#Balanceamento apenas dos dados de treino com SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE()\n",
    "X_train, Y_train = oversample.fit_resample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192ff3c2",
   "metadata": {},
   "source": [
    "### 🔍 Busca do Melhor K para o Modelo KNN (GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b16ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilizando o algoritimo KNN da biblioteca sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#Procurando o melhor valor para K, e o melhor F1 desse valor\n",
    "param_grid = {'n_neighbors': [3, 5, 7, 9, 11]}\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, scoring='f1')\n",
    "grid.fit(X_train, Y_train)\n",
    "\n",
    "print('\\nMelhor valor de K:\\n', grid.best_params_)\n",
    "print('\\nMelhor Recall score:\\n', grid.best_score_)\n",
    "\n",
    "#Criando o modelo de fato com o melhor K descoberto pelo grid\n",
    "#Inicializando o algoritimo em uma variavel\n",
    "knn = grid.best_estimator_\n",
    "#Ajustando o modelo aos dados\n",
    "knn.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ccafdd",
   "metadata": {},
   "source": [
    "### 📋 Avaliação do Modelo KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0949d200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observando as métricas do modelo\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "Y_prev = knn.predict(X_test)\n",
    "print('\\nAcurácia: ', accuracy_score(Y_test, Y_prev))\n",
    "print('Precisão: ', precision_score(Y_test, Y_prev))\n",
    "print('Recall: ', recall_score(Y_test, Y_prev))\n",
    "print('F1 Score: ', f1_score(Y_test, Y_prev))\n",
    "\n",
    "\n",
    "#Construindo a curva a partir das previsões feitas pelo modelo\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "RocCurveDisplay.from_predictions(Y_test, Y_prev, name='KNN')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Avaliando com a matriz de confusão\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "#Criando a matriz\n",
    "matriz_confusao = confusion_matrix(Y_test, Y_prev)\n",
    "#Visualizando a matriz de confusão\n",
    "visualizacao = ConfusionMatrixDisplay(matriz_confusao, display_labels=['Deixou o serviço', 'Não deixou o serviço'])\n",
    "visualizacao.plot()\n",
    "plt.show()\n",
    "\n",
    "#Foi considerado que esse modelo é bem ruim, nem vale a pena ajustar hiperparâmetros\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e479a6c",
   "metadata": {},
   "source": [
    "![Matriz de confusão KNN](<../gráficos/matriz de confusão knn.png>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e311d83a",
   "metadata": {},
   "source": [
    "# Relatório Final\n",
    "\n",
    "## 📘 Introdução\n",
    "\n",
    "Este relatório apresenta os resultados da modelagem preditiva aplicada ao problema de **evasão de clientes da Telecom X**. O principal objetivo foi desenvolver modelos capazes de prever quais clientes têm maior chance de cancelar seus serviços. As etapas envolvidas incluíram o tratamento e preparação dos dados, treinamento de diferentes modelos, análise de desempenho e identificação dos fatores mais influentes na evasão.\n",
    "\n",
    "## 🛠️ Metodologia\n",
    "\n",
    "### Pré-processamento\n",
    "\n",
    "- Tratamento de valores nulos: Substituição por média (para variáveis numéricas).\n",
    "\n",
    "- Encoding de variáveis:\n",
    "    - Binárias: substituídas por 0 e 1.\n",
    "    - Categóricas com múltiplos valores: transformadas por One-Hot Encoding.\n",
    "\n",
    "- Criação de novas variáveis:\n",
    "    - has.PhoneService e has.InternetService: sinalizam se o cliente possui algum serviço básico ativo.\n",
    "\n",
    "- Normalização: Aplicada via MinMaxScaler para modelos sensíveis à escala.\n",
    "\n",
    "- Balanceamento da base de treino: Realizado com SMOTE, para lidar com a desproporção entre classes (73,5% não saíram vs. 26,5% que saíram).\n",
    "\n",
    "### Modelos treinados\n",
    "\n",
    "Com base na matriz de confusão, foi decidido que a métrica à ser priorizada seria o Recall, que representa a taxa de verdadeiros positivos que foram classificados como positivos mesmo, visto que a taxa de dados que foi decidida minimizar foi a dos falsos negativos.\n",
    "\n",
    "- Modelo 1 – KNN (K-Nearest Neighbors)\n",
    "    Melhor K: 5\n",
    "\n",
    "    Métricas: Acurácia: \n",
    "    - **74%** / Precisão: **57%** / Recall: **53%** / F1 Score: **55%**\n",
    "\n",
    "Conclusão: Modelo com desempenho insatisfatório, especialmente no recall (foco principal).\n",
    "\n",
    "- Modelo 2 - Random Forest Classifier\n",
    "    Parâmetros ajustados via GridSearch: \n",
    "    - n_estimators: **150** / max_depth: **10** / min_samples_split: **2** / min_samples_leaf: **2**\n",
    "\n",
    "\n",
    "    Class weight ajustado para reduzir falsos negativos: {0: 2, 1: 1}\n",
    "\n",
    "\n",
    "    Métricas com 17 features mais importantes: Acurácia: \n",
    "    - **80%** / Precisão: **66%** / Recall: **72%** / F1 Score: **69%**\n",
    "\n",
    "Conclusão: Melhor modelo para o objetivo do problema (maximizar o recall).\n",
    "\n",
    "## 🔍 Análise de Importância das Variáveis\n",
    "\n",
    "- As 10 variáveis mais relevantes no modelo de Floresta foram:\n",
    "\n",
    "| Rank | Variável                               | Descrição                                                  |\n",
    "| ---- | -------------------------------------- | ---------------------------------------------------------- |\n",
    "| 1    | `account.Contract_Month-to-month`      | Contrato mensal: forte indicativo de churn                 |\n",
    "| 2    | `account.tenure`                       | Tempo como cliente: quanto menor, maior o risco            |\n",
    "| 3    | `account.MonthlyCharges`               | Cobrança mensal: valores altos correlacionam com evasão    |\n",
    "| 4    | `has.InternetService`                  | Clientes com internet são mais sensíveis ao serviço        |\n",
    "| 5    | `internet.InternetService_Fiber optic` | Clientes de fibra óptica apresentaram maior evasão         |\n",
    "| 6    | `account.PaperlessBilling`             | Cobrança sem papel aumenta risco de evasão                 |\n",
    "| 7    | `internet.OnlineSecurity`              | Clientes com segurança online tendem a permanecer mais     |\n",
    "| 8    | `customer.Partner`                     | Clientes sem parceiro têm maior probabilidade de sair      |\n",
    "| 9    | `account.TotalCharges`                 | Menores valores totais acumulados sugerem menos fidelidade |\n",
    "| 10   | `internet.TechSupport`                 | Suporte técnico reduz a chance de evasão                   |\n",
    "\n",
    "\n",
    "- Com base na análise dos gráficos de correlação e nas variáveis mais relevantes identificadas pelo modelo preditivo, observou-se que é fundamental priorizar a atenção aos clientes com menor tempo de vínculo com a empresa. Clientes com contratos do tipo mês a mês apresentam uma propensão significativamente maior à evasão, uma vez que possuem maior liberdade e facilidade para cancelar o serviço a qualquer momento.\n",
    "\n",
    "- Esse padrão é reforçado pela influência direta do tempo total de contrato (tenure) sobre o churn: quanto menor o tempo de permanência, maior o risco de cancelamento. Isso indica que os primeiros meses da jornada do cliente são críticos e exigem ações estratégicas para aumentar o engajamento e a fidelização.\n",
    "\n",
    "- Outro fator de destaque é o valor da cobrança mensal, que demonstrou forte correlação com os contratos de curta duração. Cobranças elevadas, especialmente em contratos mensais, podem contribuir para a insatisfação e impulsionar a decisão de cancelamento. Portanto, ofertas mais flexíveis e ajustadas ao perfil de consumo desses clientes podem ser uma medida eficaz para reduzir a evasão.\n",
    "\n",
    "\n",
    "## 🎯 Estratégias de Retenção com Base nos Resultado\n",
    "\n",
    "- **Campanhas de incentivo à migração para contratos de longo prazo** (trimestral ou anual), oferecendo descontos progressivos ou bônus (como dados extras, meses gratuitos ou upgrades de serviço).\n",
    "\n",
    "- **Comunicação segmentada com foco nos benefícios da fidelidade**, segurança e estabilidade de preços em contratos mais longos.\n",
    "\n",
    "- **Implantar um programa de onboarding personalizado**, com suporte técnico inicial e materiais educativos sobre o uso do serviço.\n",
    "\n",
    "- **Oferecer benefícios exclusivos para pagamentos antecipados ou combo de serviços**, agregando valor à experiência e diluindo a percepção de custo elevado.\n",
    "\n",
    "- **Realizar contato proativo nos primeiros 30 dias**, via e-mail ou ligação, para garantir satisfação e resolver eventuais problemas rapidamente.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
